## 话题模型 ##

在之前的章节中，我们用聚类方法来将文档进行分组。 聚类会给每个文档指定唯一一个分组。 但对于本书：利用Python构建机器学习系统。 究竟应该属于哪个类呢？ 在本章中，我们将要学习如何将文档归入几个聚类————一个话题中。 我们也将要学习如何制定文档的中心话题的方法。 

## 潜在的狄利克雷分布（LDA） ##

- 注：在机器学习领域，有两个方法是以LDA作为所写的：潜在狄利克雷分布和线性判别模型（一种分类模型）。sklearn.lda指的是后者，对于前者，sklearn中没有对应的方法。

## 建立话题模型 ##

首先要做的是安装gensim模块，sklearn并不支持潜在狄利克雷模型。 之后我们将要使用标准的AP（Associated Press）数据库开始我们的话题模型。

    >>> from gensim import corpora, models, similarities
	>>> corpus = corpora.BleiCorpus('./data/ap/ap.dat', '/data/ap/vocab.txt

首先，我们载入所需要的对象，然后实例化一个BleiCorpus对象。 Corpus对象只是一个预先加载的词汇列表。

	>>> model = models.ldamodel.LdaModel(corpus, num_topics=100, id2word=corpus.id2word)

这样，就建立了话题模型。 我们可以通过**model[doc]**这样的语法来查看每篇文章所属的话题：

    >>> topics = [model[c] for c in corpus]
	>>> print topics[0]
	[(3, 0.023607255776894751),
	(13, 0.11679936618551275),
	(19, 0.075935855202707139),
	(92, 0.10781541687001292)]

这样，我们就得到了文档所属于的话题以及属于某个话题的几率。



